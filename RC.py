import streamlit as st
import pandas as pd
import datetime
import altair as alt
import numpy as np
import io
import re
import textwrap, os, re, io, json, math, datetime as dt
from typing import List, Dict, Optional, Tuple
import json
import re
from pathlib import Path

st.markdown("""
    <style>
    .refresh-button {
        position: fixed;
        top: 10px;
        right: 10px;
        z-index: 100;
    }
    </style>
    <div class="refresh-button">
        <form action="" method="get">
            <button type="submit"> Refresh</button>
        </form>
    </div>
""", unsafe_allow_html=True)

hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .css-1dp5vir {display: none;} 
    </style>
"""

st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.set_page_config(layout="wide")
st.title("ğŸ“‘ Rate Card Generator")

# 1) æ”¾åœ¨æ–‡ä»¶æœ€ä¸Šæ–¹ï¼šåˆå§‹åŒ–å¼€å…³
if "hide_intro" not in st.session_state:
    st.session_state["hide_intro"] = False  # åˆå§‹æ˜¾ç¤ºæ¨ªå¹…

def intro_banner():
    # st.markdown("""
    # <div style='padding: 1rem; border-radius: 0.5rem; background-color: #F0F7F6;'>
    #   <h3 style='color: #225560;'>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨Rate Cardç”Ÿæˆå™¨</h3>
    #   <p style='font-size:16px; color:#444;'>
    #     ğŸ‘‰ ä¸Šä¼ å‰æ³¨æ„äº‹é¡¹:

    #     1. æ¯ä¸ªExcelçš„è¡¨å¤´éƒ½åœ¨ç¬¬ä¸€è¡Œï¼Œå³æ²¡æœ‰éšè—è¡Œï¼ˆç‰¹åˆ«æ³¨æ„TrainCost_Xi'anï¼‰  
    #     2. ä¸€ä¸ªExcelä¸­åªæœ‰ä¸€è¡Œè¡¨å¤´ï¼ˆç‰¹åˆ«æ³¨æ„TrainCost_Chengduï¼‰  
    #     3. æ‹–è½¦è´¹ä»ç¬¬ä¸‰å¼ sheetå¼€å§‹è¯»å–  
    #   </p>
    #   

    #   </p>
    # </div>
    # """, unsafe_allow_html=True)
    st.markdown("""
        <div style='padding: 1rem; border-radius: 0.5rem; background-color: #F0F7F6;'>
        <h3 style='color: #225560;'>âš ï¸ ä¸Šä¼ å‰æ³¨æ„äº‹é¡¹</h3>
        <div style='font-size:16px; color:#333; line-height:1.8; margin-left:0.2rem;'>
            1. æ¯ä¸ªExcelçš„è¡¨å¤´éƒ½åœ¨ç¬¬ä¸€è¡Œï¼Œå³æ²¡æœ‰éšè—è¡Œï¼ˆç‰¹åˆ«æ³¨æ„ TrainCost_Xi'anï¼‰<br>
            2. ä¸€ä¸ªExcelä¸­åªæœ‰ä¸€è¡Œè¡¨å¤´ï¼ˆç‰¹åˆ«æ³¨æ„ TrainCost_Chengduï¼‰<br>
            3. æ‹–è½¦è´¹ä»ç¬¬ä¸‰å¼  sheet å¼€å§‹è¯»å–<br>
            4. è¯·ç¡®è®¤ Route å†…å®¹ä¸ºä¼ ç»Ÿ<b>çº¿è·¯<b>
        </div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("<div style='height:28px;'></div>", unsafe_allow_html=True)

# 2) é¡µé¢é¡¶éƒ¨ï¼šæŒ‰å¼€å…³æ˜¾ç¤º/éšè—æ¨ªå¹…
if not st.session_state["hide_intro"]:
    intro_banner()
# -------- Sidebar Uploads --------
with st.sidebar:
    st.header("Upload files")
    train_files = st.file_uploader("Train Cost (support multiple files)", type=["xls", "xlsx"], accept_multiple_files=True)
    truck_file = st.file_uploader("Truckï½œæ‹–è½¦è´¹", type=["xls", "xlsx"])
    buffer_file = st.file_uploader("Buffer", type=["xls", "xlsx"])
    # st.markdown("---")
    st.markdown("> è¯´æ˜ï¼šæœ¬åº”ç”¨**ä¸ä¿å­˜**ä»»ä½•æ•°æ®ï¼›æ‰€æœ‰å¤„ç†éƒ½åœ¨å†…å­˜å®Œæˆã€‚")
    # ğŸ‘‰ æŒ‰é’®æ§åˆ¶æ˜¾ç¤º/éšè—é€»è¾‘è¯´æ˜
    if "show_logic" not in st.session_state:
        st.session_state["show_logic"] = False

    if st.button("ğŸ“– æŸ¥çœ‹ç³»ç»Ÿå¤„ç†é€»è¾‘", use_container_width=True):
        st.session_state["show_logic"] = not st.session_state["show_logic"]

    if st.session_state["show_logic"]:
        st.markdown("""
        ### ç³»ç»Ÿå¤„ç†é€»è¾‘
        1. **ä¸Šä¼ æ–‡ä»¶**ï¼šéœ€è¦ä¸Šä¼  Train Costï¼ˆå¯å¤šæ–‡ä»¶ï¼‰ã€Truckï¼ˆæ‹–è½¦è´¹ï¼‰ã€Buffer ä¸‰ç±»è¡¨æ ¼ã€‚  
        2. **Train Cost**ï¼šåªä¿ç•™æœˆåˆä»·æ ¼ï¼Œ`Valid To` è‡ªåŠ¨æ”¹æˆæœˆåº•ï¼Œåˆå¹¶å®Œæˆåçš„`Cost`å·²åŒ…å«leasing/additional costã€‚
        3. **Truck**ï¼šä»ç¬¬ 3 ä¸ª sheet å¼€å§‹è¯»ï¼Œæ¢ç®—æ—¶æ•ˆä¸ºå¤©ï¼ŒCost è‡ªåŠ¨é™¤ä»¥æ±‡ç‡ã€‚  
        4. **Buffer**ï¼šæ”¯æŒåœ¨ç½‘é¡µç«¯ç¼–è¾‘ã€‚
        5. **ç”Ÿæˆæ€»è¡¨**ï¼šä»¥Bufferè¡¨ä¸­çš„çº¿è·¯ä¸ºå‡†ï¼Œä¸Train Costä»·æ ¼åˆå¹¶ï¼Œæœ€åä¸æ‹–è½¦è´¹åˆå¹¶ï¼Œå¾—åˆ° T-Tã€D-Tã€T-D ä¸‰ç§æœåŠ¡èŒƒå›´ä»·æ ¼ã€‚  
        6. **ç‰¹æ®Šè§„åˆ™**ï¼šå‡ºå£ W å‡ Handling Fee 200 RMBï¼Œè·¯çº¿åå’Œç«™ç‚¹åšç‰¹æ®Šè°ƒæ•´ï¼ˆå¦‚é©¬æ‹‰-ç½—å…¹ï¼‰ã€‚  
        7. **è¾“å‡ºç»“æœ**ï¼šå¯ä¸‹è½½ CSVï¼Œä¹Ÿå¯å¯¼å‡ºç¦»çº¿ HTMLã€‚  
        """)

# ---------- Column picking logic ----------
STD_COLS = {
    "Flow": ["Flow"],
    "Origin Terminal": ["Origin Terminal", "origin terminal", "origin", "pol", "å§‹å‘ç«™", "èµ·è¿ç«™"],
    "Route": ["Route", "Routing","route", "çº¿è·¯", "å»ç¨‹"],
    "Dest Terminal": ["dest terminal", "destination terminal", "pod", "ç›®çš„ç«™", "åˆ°è¾¾ç«™"],
    "Service Scope": ["service scope", "scope", "æœåŠ¡èŒƒå›´"],
    "Lead-Time(Day)": ["lead-time(day)", "lead time", "transit", "tt", "æ—¶æ•ˆ", "å¤©"],
    "Container Type": ["Container", "container type", "Container Type"],
    "Valid From": ["Valid From", "valid from", "èµ·å§‹", "æœ‰æ•ˆæœŸè‡ª"],
    "Valid To": ["Valid To", "æˆªæ­¢", "æœ‰æ•ˆæœŸè‡³"],
    "remark": ["remark", "remarks", "å¤‡æ³¨", "è¯´æ˜"]
}

NEED_ORDER = ["Flow", "Origin Terminal","Route","Dest Terminal","Service Scope","Lead-Time(Day)","Container Type", "cost", "Valid From","Valid To","remark"]

def pick_first_match(colnames, patterns):
    # ç¡®ä¿åˆ—åéƒ½æ˜¯å­—ç¬¦ä¸²
    colnames = [str(c) for c in colnames]
    col_lower_map = {c.lower().strip(): c for c in colnames}
    for p in patterns:
        if p.lower() in col_lower_map:
            return col_lower_map[p.lower()]
        for c in colnames:
            if p.lower() in c.lower():
                return c
    return None

# def detect_cost_col(colnames):
#     colnames = [str(c) for c in colnames]
#     for c in colnames:
#         lc = c.lower()
#         if "cost" in lc and "forecast" not in lc:
#             return c
#     return None

def detect_leasing_col(colnames):
    colnames = [str(c) for c in colnames]
    for c in colnames:
        if "leasing" in c.lower():
            return c
    return None

# # ç”¨æ‹¬å·æŠŠæ•´ä¸ªæ•°å­—æ¨¡å¼åŒ…èµ·æ¥ï¼ˆæœ‰ä¸€ä¸ªæ•è·ç»„ï¼‰
RE_NUM_ALL = re.compile(r"[-+]?(?:\d{1,3}(?:,\d{3})+|\d+)(?:\.\d+)?")

# ç»Ÿä¸€ï¼šæŠŠåˆ—åé‡Œçš„ \n / ä¸é—´æ–­ç©ºæ ¼ / å¤šç©ºæ ¼ å»æ‰
def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    def norm(c):
        c = str(c).replace("\u00A0", " ")   # nbsp
        c = c.replace("\n", " ")
        c = re.sub(r"\s+", " ", c)
        return c.strip()
    df = df.copy()
    df.columns = [norm(c) for c in df.columns]
    return df

# æ¸…ç†ï¼šæŠŠâ€œè¡¨å¤´æ–‡å­—è·‘åˆ°æ•°æ®é‡Œâ€çš„è¡Œå»æ‰ï¼ˆå¦‚æŸæ ¼ = è¯¥åˆ—åˆ—åï¼‰
def _drop_header_rows(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in df.columns:
        mask = df[c].astype(str).str.strip().str.lower() == str(c).strip().lower()
        df = df.loc[~mask]
    return df

def normalize_train_cost(df: pd.DataFrame, source_file: str) -> pd.DataFrame:
    # â˜… æ–°å¢ï¼šæ ‡å‡†åŒ–åˆ—å + å»æ‰è¯¯å…¥çš„æ•°æ®è¡¨å¤´è¡Œ
    df = _normalize_columns(df)
    df = _drop_header_rows(df)

    cols = [str(c) for c in df.columns.tolist()]
    out = pd.DataFrame()

    # 1) å›ºå®šå­—æ®µæ˜ å°„ï¼ˆåŸæ¥çš„ STD_COLS ä¸ç”¨æ”¹ï¼›åˆ—åå·²è¢«æ ‡å‡†åŒ–ï¼Œ\n å·²å˜ç©ºæ ¼ï¼‰
    for name in ["Flow","Origin Terminal","Route","Dest Terminal","Service Scope","Lead-Time(Day)","Container Type","Valid From","Valid To","remark"]:
        pats = STD_COLS.get(name, [name])
        col = pick_first_match(cols, pats)
        out[name] = df[col] if col else np.nan

    # 2) Lead-Time(Day) æ•°å€¼åŒ–
    if "Lead-Time(Day)" in out.columns:
        out["Lead-Time(Day)"] = pd.to_numeric(out["Lead-Time(Day)"], errors="coerce")

    # 3) æå–æ•°å­—çš„å°å·¥å…·ï¼ˆä¿ç•™ä½ çš„å®ç°ï¼‰
    def _num(s: pd.Series) -> pd.Series:
        s = s.astype(str).str.replace("\u00A0", " ", regex=False)
        s = s.str.replace(r"\(([^)]+)\)", r"-\1", regex=True).str.strip()
        lists = s.str.findall(RE_NUM_ALL)
        def _avg(lst):
            if not lst:
                return 0.0
            vals = [float(x.replace(",", "")) for x in lst]
            return float(np.mean(vals))
        return lists.apply(_avg).astype(float)

    # 4) leasing
    leasing_col = detect_leasing_col(cols)
    leasing_num = _num(df[leasing_col]) if leasing_col else pd.Series(0.0, index=df.index)
    out["leasing"] = leasing_num

    # 5) costï¼šæŠŠæ‰€æœ‰å« costï¼ˆæ’é™¤ forecastï¼‰çš„åˆ—ç›¸åŠ 
    cost_cols = [c for c in cols if ("cost" in c.lower()) and ("forecast" not in c.lower())]
    if cost_cols:
        parts = [_num(df[c]).rename(c) for c in cost_cols]
        cost_sum = pd.concat(parts, axis=1).sum(axis=1)
    else:
        cost_sum = pd.Series(0.0, index=df.index)
    out["cost"] = cost_sum + leasing_num

    # 6) Container Type å…œåº•ï¼ˆåˆ—åå·²æ ‡å‡†åŒ–ï¼Œè¿™æ­¥ä»ç„¶ä¿ç•™æ›´ç¨³ï¼‰
    container_cols = [c for c in cols if "container" in c.lower()]
    if container_cols:
        tmp = df[container_cols].astype(str).replace({"nan": np.nan, "None": np.nan}).bfill(axis=1)
        out["Container Type"] = tmp.iloc[:, 0].astype(str).str.strip()
        out.loc[out["Container Type"].isin(["", "nan", "None"]), "Container Type"] = np.nan

    # 7) æ–‡æœ¬åˆ—å»ç©ºæ ¼ & ç»Ÿä¸€å¤§å°å†™ï¼ˆå¯é€‰ï¼šæŠŠ Flow ç»Ÿä¸€æˆå¤§å†™ï¼‰
    for c in ["Flow","Origin Terminal","Route","Dest Terminal","Service Scope","Valid From","Valid To","remark","Container Type"]:
        if c in out.columns:
            out[c] = out[c].astype(str).str.strip()
    if "Flow" in out.columns:
        out["Flow"] = out["Flow"].astype(str).str.upper().str.strip()

    # 8) åˆ—é¡ºåº
    ordered = [c for c in NEED_ORDER if c in out.columns]
    if "Container Type" in out.columns and "Container Type" not in ordered:
        ordered.append("Container Type")
    out = out.reindex(columns=ordered)

    # å¦‚éœ€éšè—ä¸­é—´åˆ—ï¼Œä¿ç•™ä½ åŸæ³¨é‡Šï¼š
    out.drop(columns=["leasing"], inplace=True, errors="ignore")

    out["__source_file__"] = source_file
    return out


# ---------- Main ----------
def build_total_cost_table(df_buffer, df_train, df_truck,
                           remark_text: str = "",
                           payload40: float = None,
                           overload_text: str = "",
                           note_text: str = "") -> pd.DataFrame:
    # ---------- å°å·¥å…· ----------
    def _norm_cols(df):
        d = df.copy()
        d.columns = [c.strip() for c in d.columns]
        return d

    def _as_num(s):
        return pd.to_numeric(s, errors="coerce")
    # ---------- ç»Ÿä¸€åˆ—åç©ºæ ¼/å¤§å°å†™ ----------
    df_buffer = _norm_cols(df_buffer)
    df_train  = _norm_cols(df_train)
    df_truck  = _norm_cols(df_truck)

    # å…³é”®å­—æ®µç»Ÿä¸€ä¸º string å»ç©ºæ ¼ï¼Œé¿å…åˆå¹¶æ—¶åŒ¹é…å¤±è´¥
    for d in (df_buffer, df_train, df_truck):
        for k in ["Origin Terminal", "Route", "Dest Terminal", "Container Type"]:
            if k in d.columns:
                d[k] = d[k].astype("string").str.strip()

    # ---------- 1) Buffer + Train å››é”®åˆå¹¶ï¼Œå¾—åˆ° T-T åŸºç¡€ ----------
    merge_keys = ["Origin Terminal", "Route", "Dest Terminal", "Container Type"]
    missing_in_buffer = [k for k in merge_keys if k not in df_buffer.columns]
    missing_in_train  = [k for k in merge_keys if k not in df_train.columns]
    if missing_in_buffer:
        raise ValueError(f"Buffer ç¼ºå°‘å­—æ®µ: {missing_in_buffer}")
    if missing_in_train:
        raise ValueError(f"Train ç¼ºå°‘å­—æ®µ: {missing_in_train}")

    tt_base = df_buffer.merge(
        df_train,
        on=merge_keys,
        how="inner",
        suffixes=("", "_train")
    )

    # æ•°å€¼åŒ–
    if "Buffer" not in tt_base.columns:
        raise ValueError("Buffer è¡¨ä¸­ç¼ºå°‘ 'Buffer' åˆ—")
    for c in ["Buffer", "cost", "leasing", "Lead-Time(Day)"]:
        if c in tt_base.columns:
            tt_base[c] = _as_num(tt_base[c]).fillna(0)

    # T-T æˆæœ¬ï¼ˆæŒ‰ä½ çš„å£å¾„ï¼šBuffer + cost(åŒ…å«leasing)ï¼‰
    tt_base["TT_total"] = tt_base["Buffer"].fillna(0) + tt_base["cost"].fillna(0)
    # T-T æ—¶æ•ˆ = çº¯ç«è½¦æ®µæ—¶æ•ˆ
    tt_base["TT_leadtime"] = tt_base["Lead-Time(Day)"].fillna(0)

    # ç»„è£… T-T è®°å½•ï¼ˆCity/Province ç½®ç©ºï¼‰
    tt_final = pd.DataFrame({
        "Flow": tt_base["Flow"],
        "Pickup/Delivery City": "",
        "Province": "",
        "Origin Terminal": tt_base["Origin Terminal"],
        "Dest Terminal": tt_base["Dest Terminal"],
        "Route": tt_base["Route"],
        "Service Scope": "T-T",
        "Lead-Time(Day)": tt_base["TT_leadtime"],
        "Valid From": tt_base["Valid From"] if "Valid From" in tt_base.columns else "",
        "Valid To": tt_base["Valid To"] if "Valid To" in tt_base.columns else "",
        "Total Cost": tt_base["TT_total"]
    })

    def pick_col(df, candidates, default_val=""):
        for c in candidates:
            if c in df.columns:
                return df[c]
        return pd.Series([default_val] * len(df), index=df.index)

    # ---------- 2) D-Tï¼ˆå‡ºå£ï¼ŒWï¼‰ï¼šåŸå¸‚â†’å§‹å‘ç«™ çš„æ‹–è½¦ + T-T ----------
    truck_w = df_truck[df_truck["Route"].astype(str).str.upper().str.strip() == "W"].copy()
    tt_w    = tt_base[tt_base["Flow"].astype(str).str.upper().str.strip() == "W"].copy()

    dt_merge = tt_w.merge(
        truck_w,
        on="Origin Terminal",
        how="left",
        suffixes=("", "_truck")
    )

    # å…¼å®¹ä¸åŒåˆ—åï¼ˆæ˜¯å¦å¸¦ _truck åç¼€ï¼‰
    dt_merge["truck_cost"] = pd.to_numeric(pick_col(dt_merge, ["Cost_truck", "Cost"], 0), errors="coerce").fillna(0)
    dt_merge["truck_lt"]   = pd.to_numeric(pick_col(dt_merge, ["Lead-Time (Day)_truck", "Lead-Time (Day)"], 0), errors="coerce").fillna(0)
    dt_merge["DT_total"]    = dt_merge["TT_total"] + dt_merge["truck_cost"]
    dt_merge["DT_leadtime"] = dt_merge["TT_leadtime"] + dt_merge["truck_lt"]

    dt_final = pd.DataFrame({
        "Flow": dt_merge["Flow"],
        "Pickup/Delivery City": pick_col(dt_merge, ["Pickup/Delivery City", "Pickup/Delivery City_truck"]),
        "Province": pick_col(dt_merge, ["Province", "Province_truck"]),
        "Origin Terminal": dt_merge["Origin Terminal"],
        "Dest Terminal": dt_merge["Dest Terminal"],
        "Route": dt_merge["Route"],
        "Service Scope": "D-T",
        "Lead-Time(Day)": dt_merge["DT_leadtime"],
        "Valid From": pick_col(dt_merge, ["Valid From"], ""),
        "Valid To": pick_col(dt_merge, ["Valid To"], ""),
        "Total Cost": dt_merge["DT_total"],
    })

    # ---------- 3) T-Dï¼ˆè¿›å£ï¼ŒEï¼‰ï¼šåˆ°è¾¾ç«™â†’åŸå¸‚ çš„æ‹–è½¦ + T-T ----------
    truck_e = df_truck[df_truck["Route"].astype(str).str.upper().str.strip() == "E"].copy()
    tt_e    = tt_base[tt_base["Flow"].astype(str).str.upper().str.strip() == "E"].copy()

    td_merge = tt_e.merge(
        truck_e,
        left_on="Dest Terminal",
        right_on="Origin Terminal",
        how="left",
        suffixes=("", "_truck")
    )

    td_merge["truck_cost"] = pd.to_numeric(pick_col(td_merge, ["Cost_truck", "Cost"], 0), errors="coerce").fillna(0)
    td_merge["truck_lt"]   = pd.to_numeric(pick_col(td_merge, ["Lead-Time (Day)_truck", "Lead-Time (Day)"], 0), errors="coerce").fillna(0)

    # æ³¨æ„ï¼šåˆå¹¶åå·¦è¡¨çš„ç«è½¦â€œå§‹å‘ç«™â€åœ¨ 'Origin Terminal'ï¼Œ
    # å³è¡¨å¡è½¦çš„â€œèµ·ç‚¹ç«™â€ï¼ˆç­‰äºç«è½¦çš„åˆ°è¾¾ç«™ï¼‰åœ¨ 'Origin Terminal_truck'
    td_merge["TD_total"]    = td_merge["TT_total"] + td_merge["truck_cost"]
    td_merge["TD_leadtime"] = td_merge["TT_leadtime"] + td_merge["truck_lt"]

    td_final = pd.DataFrame({
        "Flow": td_merge["Flow"],
        "Pickup/Delivery City": pick_col(td_merge, ["Pickup/Delivery City", "Pickup/Delivery City_truck"]),
        "Province": pick_col(td_merge, ["Province", "Province_truck"]),
        # å–ç«è½¦â€œå§‹å‘ç«™â€ï¼ˆå·¦è¡¨ï¼‰
        "Origin Terminal": pick_col(td_merge, ["Origin Terminal"]),
        "Dest Terminal": td_merge["Dest Terminal"],
        "Route": td_merge["Route"],
        "Service Scope": "T-D",
        "Lead-Time(Day)": td_merge["TD_leadtime"],
        "Valid From": pick_col(td_merge, ["Valid From"], ""),
        "Valid To": pick_col(td_merge, ["Valid To"], ""),
        "Total Cost": td_merge["TD_total"],
    })


    # ---------- 4) åˆå¹¶ä¸‰ç±»è®°å½• ----------
    final_df = pd.concat([tt_final, dt_final, td_final], ignore_index=True)

    # ---------- 5) Handling Fee ----------
    mask_w   = final_df["Flow"].astype(str).str.upper().str.strip() == "W"
    # åªå¯¹ W çš„è¡Œå‡ 200
    final_df.loc[final_df["Flow"] == "W", "Total Cost"] -= 200
    final_df["Handling Fee"] = np.where(final_df["Flow"].astype(str).str.upper().str.strip() == "W", 200, 0)

    # ---------- 6) åˆ—é¡ºåºä¸æ•°å€¼ç±»å‹ ----------
    final_df["Lead-Time(Day)"] = _as_num(final_df["Lead-Time(Day)"])
    final_df["Total Cost"]     = _as_num(final_df["Total Cost"])
    # final_df = final_df[[c for c in final_cols if c in final_df.columns]]
    final_df["Route"] = final_df["Route"].replace({
        "ä¼ ç»Ÿçº¿è·¯": "Public",
        "ä¼ ç»Ÿè·¯çº¿": "Public",
        "å…¨ç¨‹æ—¶åˆ»è¡¨": "Super Express"
    })
    def _norm(s: pd.Series) -> pd.Series:
        return (s.astype(str)
                .str.strip()
                .str.replace(r"[\u2018\u2019\u2032]", "'", regex=True)  
                .str.replace(r"[\u2013\u2014\u2212]", "-", regex=True) 
                .str.upper())

    # 1. æˆéƒ½ â†’ Lodz çš„ Super Express æ”¹æˆ æˆéƒ½ â†’ Malaszewicze çš„ Super Express
    mask_out = (
        _norm(final_df["Origin Terminal"]).eq("CHENGDU") &
        _norm(final_df["Dest Terminal"]).eq("LODZ") &
        _norm(final_df["Route"]).eq("SUPER EXPRESS")
    )
    final_df.loc[mask_out, "Dest Terminal"] = "Malaszewicze"

    # 2. Lodz â†’ æˆéƒ½ çš„ Super Express æ”¹æˆ Malaszewicze â†’ æˆéƒ½ çš„ Super Express
    mask_in = (
        _norm(final_df["Origin Terminal"]).eq("LODZ") &
        _norm(final_df["Dest Terminal"]).eq("CHENGDU") &
        _norm(final_df["Route"]).eq("SUPER EXPRESS")
    )
    final_df.loc[mask_in, "Origin Terminal"] = "Malaszewicze"


    # ---------- Remark & å…¨å±€é™„åŠ åˆ— ----------
    final_df["Remark"] = remark_text or ""
    final_df["Extra Cost of Overload"] = overload_text or ""
    mask_cd_ml = (
    ((final_df["Origin Terminal"] == "Chengdu") & (final_df["Dest Terminal"] == "Malaszewicze")) |
    ((final_df["Origin Terminal"] == "Malaszewicze") & (final_df["Dest Terminal"] == "Chengdu")))
    final_df["Note"] = np.where(mask_cd_ml, note_text, "")
    final_df["40' Payload Limited (ton)"] = payload40 if payload40 is not None else ""

    # ---------- åˆ—é¡ºåº ----------
    ordered_cols = [
        "Flow","Pickup/Delivery City","Province","Origin Terminal","Dest Terminal","Route",
        "Service Scope","Lead-Time(Day)","Valid From","Valid To",
        "Total Cost","Handling Fee",
        "40' Payload Limited (ton)","Extra Cost of Overload",
        "Note","Remark"
    ]
    final_df = final_df[[c for c in ordered_cols if c in final_df.columns]]
    return final_df

tab1, tab2 = st.tabs(["Data", "Text"])
# ---------- Train Data Processing ----------
with tab1:
    st.number_input("USD:CNY Rate", min_value=0.0, step=0.01, value=7.0, key="rate")
    if train_files:
        dfs = []
        for f in train_files:
            try:
                df_raw = pd.read_excel(f)
            except Exception:
                f.seek(0)
                df_raw = pd.read_excel(f, sheet_name=0, engine="openpyxl")
            norm = normalize_train_cost(df_raw, f.name)
            dfs.append(norm)
        all_train = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(columns=NEED_ORDER)
        df_train = all_train.dropna(how="all") 
        df_train = df_train.dropna(subset=["cost"])
        # 1) è§„èŒƒæ—¥æœŸåˆ—
        df_train["Valid From"] = pd.to_datetime(df_train["Valid From"], errors="coerce")
        df_train["Valid To"]   = pd.to_datetime(df_train["Valid To"],   errors="coerce")

        # 2) ä»…ä¿ç•™ Valid From åœ¨æ¯æœˆ 1 å·çš„ä»·æ ¼
        mask_first = df_train["Valid From"].dt.day == 1
        df_train = df_train.loc[mask_first].copy()

        # 3) æŠŠ Valid To è®¾ä¸ºå½“æœˆæœ€åä¸€å¤©
        df_train["Valid To"] = df_train["Valid From"] + pd.offsets.MonthEnd(0)

        df_train["Valid From"] = df_train["Valid From"].dt.date
        df_train["Valid To"]   = df_train["Valid To"].dt.date
        with st.expander("æŸ¥çœ‹åˆå¹¶åçš„Train Cost"):
            st.success(f"Train Cost å·²åŠ è½½ï¼Œåˆå¹¶å {len(df_train)} è¡Œã€‚")
            # df_train = st.data_editor(df_train, use_container_width=True)
            st.dataframe(df_train[NEED_ORDER], use_container_width=True)
            
    # ---------- Truck Data Processing ----------
    if truck_file:
        dfs_truck = []
        xls = pd.ExcelFile(truck_file)  # è¯»å– Truck æ–‡ä»¶
        sheets = xls.sheet_names[2:]  # ä»ç¬¬ä¸‰ä¸ª sheet å¼€å§‹è¯»å–
        for sheet in sheets:
            df_truck_raw = pd.read_excel(xls, sheet_name=sheet)
            dfs_truck.append(df_truck_raw)
        all_truck = pd.concat(dfs_truck, ignore_index=True) if dfs_truck else pd.DataFrame()
        # å»æ‰ç©ºç™½åˆ—
        all_truck = all_truck.dropna(axis=1, how='all')
        # å»æ‰ç©ºç™½è¡Œ
        all_truck = all_truck.dropna(axis=0, how='all')
        if 'Lead-Timeï¼ˆhour)' in all_truck.columns:
            all_truck['Lead-Time (Day)'] = np.ceil(all_truck['Lead-Timeï¼ˆhour)'] / 24).astype(int)
            all_truck.drop('Lead-Timeï¼ˆhour)', axis=1, inplace=True)
        # ä¿®æ”¹åˆ—å
        origin_col = [col for col in all_truck.columns if 'origin terminal' in col.lower()]
        if origin_col:
            all_truck['Origin Terminal'] = all_truck[origin_col]
            all_truck.drop(origin_col, axis=1, inplace=True)  
        route_col = [col for col in all_truck.columns if 'route' in col.lower()]
        if route_col:
            all_truck['Route'] = all_truck[route_col]
            all_truck.drop(route_col, axis=1, inplace=True)  
        pro_col = [col for col in all_truck.columns if 'province' in col.lower()]
        if pro_col:
            all_truck['Province'] = all_truck[pro_col]
            all_truck.drop(pro_col, axis=1, inplace=True)  

        # å¤„ç† cost åˆ—ï¼Œæ‰¾åˆ°åŒ…å« cost çš„åˆ—å¹¶é™¤ä»¥ 7
        usd_cny = float(st.session_state.get("rate", 7.0) or 7.0) 
        cost_col = [col for col in all_truck.columns if 'cost' in col.lower()]
        if cost_col:
            all_truck['Cost'] = np.round(all_truck[cost_col[0]] / usd_cny).astype(int)
            all_truck.drop(cost_col[0], axis=1, inplace=True)
        all_truck['Valid From'] = pd.to_datetime(all_truck['Valid From'], errors='coerce').dt.date
        all_truck['Valid To'] = pd.to_datetime(all_truck['Valid To'], errors='coerce').dt.date
        # Reorder columns
        column_order = [
            "Route",
            "Origin Terminal",
            "Pickup/Delivery City",
            "Province",
            "Lead-Time (Day)",
            "Valid From",
            "Valid To",
            "Cost"
        ]
        # Reorder the columns as per the new column_order list
        #df_truck = all_truck[column_order] if all(col in all_truck.columns for col in column_order) else all_truck
        df_truck = all_truck[column_order]
        # æ˜¾ç¤ºåˆå¹¶åçš„ Truck æ•°æ®
        with st.expander("æŸ¥çœ‹æ‹–è½¦è´¹æ•°æ®"):
            st.success(f"æ‹–è½¦è´¹æ•°æ®å·²åŠ è½½ï¼Œå…±{len(df_truck)} è¡Œã€‚")
            st.dataframe(df_truck, use_container_width=True)

    # ---------- Buffer Data Processing ----------
    if buffer_file:
        all_buffer = pd.read_excel(buffer_file)
        columns = ["Origin Terminal", "Route", "Dest Terminal", "Container Type", "Buffer"]
        df_buffer = all_buffer[columns]
        def _norm(s: pd.Series) -> pd.Series:
            return (s.astype(str)
                .str.strip()
                .str.replace(r"[\u2018\u2019\u2032]", "'", regex=True)  
                .str.replace(r"[\u2013\u2014\u2212]", "-", regex=True) 
                .str.upper())  # å¦‚éœ€å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
        df_buffer = df_buffer.dropna(how="all")
        mask_1 = (
            _norm(df_buffer["Origin Terminal"]).eq("MALASZEWICZE") &
            _norm(df_buffer["Dest Terminal"]).eq("CHENGDU")
            )
        df_buffer.loc[mask_1, ["Origin Terminal"]] = ["Lodz"]
        mask_2 = (
            _norm(df_buffer["Origin Terminal"]).eq("CHENGDU") &
            _norm(df_buffer["Dest Terminal"]).eq("MALASZEWICZE")
            )
        df_buffer.loc[mask_2, ["Route","Dest Terminal"]] = ["å…¨ç¨‹æ—¶åˆ»è¡¨","Lodz"]
        st.session_state.setdefault("buffer_expanded", False)  # é»˜è®¤ä¸å±•å¼€
        with st.expander("æŸ¥çœ‹Bufferæ•°æ®", expanded=st.session_state["buffer_expanded"]):
            st.success(f"Bufferæ•°æ®å·²åŠ è½½ï¼Œå…±{len(df_buffer)} è¡Œã€‚")
            # é¦–æ¬¡è¿›å…¥æ—¶ï¼ŒæŠŠåŸæ•°æ®æ”¾åˆ°ä¼šè¯é‡Œï¼Œé¿å…ç¼–è¾‘æ—¶é—ªå›
            if "buffer_edit_df" not in st.session_state:
                st.session_state["buffer_edit_df"] = df_buffer.copy()
            with st.form("buffer_edit_form"):
                edited = st.data_editor(
                    st.session_state["buffer_edit_df"],
                    use_container_width=True,
                    hide_index=True,
                    num_rows="dynamic",
                    column_config={
                        "Add_Fixed": st.column_config.NumberColumn("Add_Fixed", step=1.0, format="%.2f"),
                        "Add_Percent": st.column_config.NumberColumn("Add_Percent", step=0.01, format="%.4f",
                                            help="å¯è¾“å…¥0.05æˆ–5%ï¼›åå°å¯å†ç»Ÿä¸€ä¸ºå°æ•°"),
                        "remark": st.column_config.TextColumn("remark", max_chars=200),
                    },
                )
                saved = st.form_submit_button("ä¿å­˜ Buffer ç¼–è¾‘")
            if saved:
                st.session_state["buffer_edit_df"] = edited.copy()
                st.success("å·²ä¿å­˜ Buffer ç¼–è¾‘å†…å®¹ã€‚")
        df_buffer = st.session_state["buffer_edit_df"]

with tab2:
    st.header("Global Settings")
    defaults = {
        "payload40": 20,
        "payload20": 20,
        "overload_text": "250USD/40'/20'(20-23 ton)",
        "note_text": "Actual arrival/departure station is Lodz i/o Malaszewicze.",
        "remark_text": (
            "1. WB leadtime include CN terminal customs landing time\n"
            "2. EB leadtime exclude CN terminal customs lead time of estimated 1-2 days\n"
            "3. Overload cost in case cargo weight more than 23 ton, please check with us case by case.\n"
            "4. Due to impact of Chinese New Year, if your pre/on carriage happen in week 4 to week 7, trucking fee will increase 30%."
        )
    }
    for k, v in defaults.items():
        st.session_state.setdefault(k, v)

    st.number_input("40' Payload Limited (ton)", min_value=0, step=1, key="payload40")
    st.text_input("Extra Cost of Overload", key="overload_text")
    st.text_area("Remark", height=160, key="remark_text")

# ---------- Export HTML -------------------------------------------------------------------------
#---------------------------------------------------------------------------------------------------------------
COLUMN_MAP = {
    # ä½ å·²æœ‰çš„åŸå§‹åˆ—å â†’ HTML æœŸæœ›çš„åˆ—åï¼ˆå³è¾¹æ˜¯æœ€ç»ˆè¾“å‡ºç»™ HTML çš„é”®ï¼‰
    "From": "From",
    "Province": "Province",
    "To": "To",
    "Origin Terminal": "Origin Terminal",
    "Dest Terminal": "Dest Terminal",
    "Service Scope": "Service Scope",
    "Route": "Route",
    "Lead-Time(Day)": "Lead-Time(Day)",
    "Total Cost": "Total Cost",
    "Handling Fee": "Handling Fee",
    "Valid From": "Valid From",
    "Valid To": "Valid To",
    "40' Payload Limited (ton)": "40' Payload Limited (ton)", 
    "Extra Cost of Overload": "Extra Cost of Overload",
    "Note": "Note",
    "Remark": "Remark"
}

REQUIRED_COLS = [
    "From", "Province", "To",
    "Origin Terminal", "Dest Terminal",
    "Service Scope", "Route",
    "Lead-Time(Day)",
    "Total Cost", "Handling Fee",
    "Valid From", "Valid To",
    "40' Payload Limited (ton)",
    "Extra Cost of Overload",
    "Note","Remark"
]

def _prepare_df_for_html(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    # ç»Ÿä¸€ç”Ÿæˆ/å¤åˆ¶è¾“å‡ºåˆ—
    for src, dst in COLUMN_MAP.items():
        if src in d.columns:
            if dst != src:
                d[dst] = d[src]
        else:
            d[dst] = np.nan

    # åªä¿ç•™å‰ç«¯éœ€è¦çš„åˆ—ï¼ˆå¹¶æŒ‰é¡ºåºï¼‰
    d = d[REQUIRED_COLS]

    # æ•°å€¼åˆ—ï¼šä¿æŒä¸º float
    for col in ["Total Cost", "Handling Fee"]:
        if col in d.columns:
            d[col] = pd.to_numeric(d[col], errors="coerce").fillna(0.0).astype(float)

    # æ—¥æœŸåˆ—ï¼šè½¬æˆå­—ç¬¦ä¸²ï¼ˆé¿å… JSON åºåˆ—åŒ–æˆæ—¶é—´æˆ³æˆ– NaTï¼‰
    for col in ["Valid From", "Valid To"]:
        if col in d.columns:
            d[col] = d[col].astype(str).replace({"NaT": "", "nat": ""})

    # å…¶ä»–ç©ºå€¼ â†’ Noneï¼ˆè®© JSON ä¸º nullï¼‰
    d = d.where(pd.notna(d), None)

    return d
import json, re, base64
def inject_df_into_html(df: pd.DataFrame, template_path: str) -> str:
    html = Path(template_path).read_text(encoding="utf-8")

    # DataFrame -> JSONï¼ˆç¡®ä¿æ•°å­—æ˜¯ numberã€æ—¥æœŸæ˜¯å­—ç¬¦ä¸²ï¼‰
    payload = df.to_dict(orient="records")
    json_bytes = json.dumps(payload, ensure_ascii=False).encode("utf-8")
    b64 = base64.b64encode(json_bytes).decode("ascii")

    # ç”¨ Base64 æ³¨å…¥ï¼Œå‰ç«¯ç”¨ atob å† JSON.parseï¼Œè¿˜åŸæˆæ•°ç»„
    pattern = r"const\s+csvData\s*=\s*\[[\s\S]*?\];"
    replacement = f"const csvData = JSON.parse(atob('{b64}'));"
    new_html = re.sub(pattern, replacement, html)

    return new_html


if buffer_file and train_files and truck_file:
    # â€”â€” ç”Ÿæˆ final df â€”â€” #
    final_df = build_total_cost_table(
        df_buffer=df_buffer,
        df_train=df_train,
        df_truck=df_truck,
        remark_text=st.session_state["remark_text"],
        payload40=st.session_state["payload40"],
        overload_text=st.session_state["overload_text"],
        note_text=st.session_state["note_text"],
    )
    def _norm(s):
        if pd.isna(s):
            return ""
        return str(s).strip()

    def _norm_scope(s):
        # ç»Ÿä¸€æˆå¤§å†™ã€å»ç©ºæ ¼ã€ç»Ÿä¸€çŸ­æ¨ªçº¿
        s = _norm(s).upper().replace(" ", "")
        s = s.replace("â€”", "-").replace("â€“", "-")
        return s

    def _norm_flow(s):
        return _norm(s).upper()

    def _compute_from(row):
        flow = _norm_flow(row["Flow"])
        scope = _norm_scope(row["Service Scope"])
        # T-Tï¼šä¸¤ç«¯éƒ½æ˜¯ç«™ç‚¹
        if scope == "T-T":
            return row["Origin Terminal"]
        # å…¶å®ƒ scopeï¼šæŒ‰ W/E è§„åˆ™
        if flow == "W":
            return row["Pickup/Delivery City"]
        elif flow == "E":
            return row["Origin Terminal"]
        # å…œåº•ï¼ˆæœªçŸ¥ flowï¼‰ï¼šä¼˜å…ˆèµ·ç‚¹ç«™ï¼Œå¦åˆ™åŸå¸‚
        return row["Origin Terminal"] if _norm(row["Origin Terminal"]) else row["Pickup/Delivery City"]

    def _compute_to(row):
        flow = _norm_flow(row["Flow"])
        scope = _norm_scope(row["Service Scope"])
        if scope == "T-T":
            return row["Dest Terminal"]
        if flow == "W":
            return row["Dest Terminal"]
        elif flow == "E":
            return row["Pickup/Delivery City"]
        # å…œåº•ï¼ˆæœªçŸ¥ flowï¼‰ï¼šä¼˜å…ˆç›®çš„ç«™ï¼Œå¦åˆ™åŸå¸‚
        return row["Dest Terminal"] if _norm(row["Dest Terminal"]) else row["Pickup/Delivery City"]

    final_df["From"] = final_df.apply(_compute_from, axis=1)
    final_df["To"]   = final_df.apply(_compute_to,   axis=1)

    # å¦‚éœ€æŠŠ From/To é å‰æ˜¾ç¤ºï¼Œå¯é‡æ’åˆ—é¡ºåºï¼ˆå¯é€‰ï¼‰
    prefer_order = ["Flow", "Service Scope", "From", "To"]
    rest = [c for c in final_df.columns if c not in prefer_order]
    
    # ç”Ÿæˆdf_final
    final_df = final_df[prefer_order + rest]

    st.success(f"æ€»è¡¨ç”Ÿæˆå®Œæˆï¼š{len(final_df)} è¡Œ")

    with st.expander("é¢„è§ˆ"):
        st.dataframe(final_df, use_container_width=True)
        st.download_button(
            "ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ CSV",
            data=final_df.to_csv(index=False).encode("utf-8"),
            file_name="RC_Raw_DB.csv",
            mime="text/csv"
        )

    st.header("Export Rate Card HTML")    
    if "final_df" in globals():
        df_ready = _prepare_df_for_html(final_df)
        html_template_path = "RC.html"
        if Path(html_template_path).exists():
            if st.button("ğŸ“¤ å¯¼å‡º Rate Card HTML", use_container_width=True):
                out_html = inject_df_into_html(df_ready, html_template_path)
                st.download_button(
                    label="ä¸‹è½½ Rate Card.html",
                    data=out_html.encode("utf-8"),
                    file_name="RateCard.html",
                    mime="text/html",
                    use_container_width=True
                )
                st.success("å·²ç”Ÿæˆå¹¶å¯ä¸‹è½½ç¦»çº¿å¯ç”¨çš„ HTMLã€‚")
        else:
            st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ Rate Card.htmlï¼Œè¯·æŠŠæ¨¡æ¿æ”¾åˆ°ç¨‹åºåŒç›®å½•ã€‚")
    else:
        st.warning("final_df å°šæœªç”Ÿæˆæˆ–æœªåœ¨å½“å‰ä½œç”¨åŸŸã€‚è¯·å…ˆç”Ÿæˆ final_dfã€‚")
else:
    st.info("è¯·ä¸Šä¼ å®Œæ•´è¡¨æ ¼ã€‚")


if "final_df" in locals() and isinstance(final_df, pd.DataFrame) and not final_df.empty:
    if not st.session_state["hide_intro"]:
        st.session_state["hide_intro"] = True
        st.rerun()   # ç«‹åˆ»é‡ç»˜ï¼Œè¿™æ ·æœ¬æ¬¡å°±ä¸å†æ˜¾ç¤ºæ¨ªå¹…



