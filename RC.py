import streamlit as st
import pandas as pd
import datetime
import altair as alt
import numpy as np
import io
import re
import textwrap, os, re, io, json, math, datetime as dt
from typing import List, Dict, Optional, Tuple
import json
import re
from pathlib import Path

st.markdown("""
    <style>
    .refresh-button {
        position: fixed;
        top: 10px;
        right: 10px;
        z-index: 100;
    }
    </style>
    <div class="refresh-button">
        <form action="" method="get">
            <button type="submit"> Refresh</button>
        </form>
    </div>
""", unsafe_allow_html=True)

hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .css-1dp5vir {display: none;} 
    </style>
"""

st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.set_page_config(layout="wide")
st.title("Rate Card Generator")

# 1) æ”¾åœ¨æ–‡ä»¶æœ€ä¸Šæ–¹ï¼šåˆå§‹åŒ–å¼€å…³
if "hide_intro" not in st.session_state:
    st.session_state["hide_intro"] = False  # åˆå§‹æ˜¾ç¤ºæ¨ªå¹…

def intro_banner():
    st.markdown("""
    <div style='padding: 1rem; border-radius: 0.5rem; background-color: #F0F7F6;'>
      <h3 style='color: #225560;'>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨Rate Cardç”Ÿæˆå™¨</h3>
      <p style='font-size:16px; color:#444;'>
        æœ¬å·¥å…·å¸®åŠ©æ‚¨é€šè¿‡ <b>Train Cost</b>ã€<b>Buffer Table</b> ä¸ <b>FCL Net Cost</b>ï¼Œ
        å¿«é€Ÿç”Ÿæˆ <b>Rate Card<b>ï¼Œä½“ç°å„æ¡è·¯çº¿çš„ä»·æ ¼ã€‚
      </p>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("<div style='height:28px;'></div>", unsafe_allow_html=True)

# 2) é¡µé¢é¡¶éƒ¨ï¼šæŒ‰å¼€å…³æ˜¾ç¤º/éšè—æ¨ªå¹…
if not st.session_state["hide_intro"]:
    intro_banner()
# -------- Sidebar Uploads --------
with st.sidebar:
    st.header("Upload files")
    train_files = st.file_uploader("Train Cost|T-T (support multiple files)", type=["xls", "xlsx"], accept_multiple_files=True)
    buffer_file = st.file_uploader("Buffer", type=["xls", "xlsx"])
    truck_file = st.file_uploader("Truck|æ‹–è½¦è´¹", type=["xls", "xlsx"])
    # st.markdown("---")
    st.markdown("> è¯´æ˜ï¼šæœ¬åº”ç”¨**ä¸ä¿å­˜**ä»»ä½•æ•°æ®ï¼›æ‰€æœ‰å¤„ç†éƒ½åœ¨å†…å­˜å®Œæˆã€‚")

# ---------- Column picking logic ----------
STD_COLS = {
    "Flow": ["Flow"],
    "Origin Terminal": ["origin terminal", "origin", "pol", "å§‹å‘ç«™", "èµ·è¿ç«™"],
    "Route": ["Route", "Routing","route", "çº¿è·¯", "å»ç¨‹"],
    "Dest Terminal": ["dest terminal", "destination terminal", "pod", "ç›®çš„ç«™", "åˆ°è¾¾ç«™"],
    "Service Scope": ["service scope", "scope", "æœåŠ¡èŒƒå›´"],
    "Lead-Time(Day)": ["lead-time(day)", "lead time", "transit", "tt", "æ—¶æ•ˆ", "å¤©"],
    "valid from": ["valid from", "èµ·å§‹", "æœ‰æ•ˆæœŸè‡ª"],
    "valid to": ["valid to", "æˆªæ­¢", "æœ‰æ•ˆæœŸè‡³"],
    "remark": ["remark", "remarks", "å¤‡æ³¨", "è¯´æ˜"],
}

NEED_ORDER = ["Flow", "Origin Terminal","Route","Dest Terminal","Service Scope","Lead-Time(Day)","Container Type", "cost","leasing", "valid from","valid to","remark"]

def pick_first_match(colnames, patterns):
    # ç¡®ä¿åˆ—åéƒ½æ˜¯å­—ç¬¦ä¸²
    colnames = [str(c) for c in colnames]
    col_lower_map = {c.lower().strip(): c for c in colnames}
    for p in patterns:
        if p.lower() in col_lower_map:
            return col_lower_map[p.lower()]
        for c in colnames:
            if p.lower() in c.lower():
                return c
    return None

def detect_cost_col(colnames):
    colnames = [str(c) for c in colnames]
    for c in colnames:
        lc = c.lower()
        if "cost" in lc and "forecast" not in lc:
            return c
    return None

def detect_leasing_col(colnames):
    colnames = [str(c) for c in colnames]
    for c in colnames:
        if "leasing" in c.lower():
            return c
    return None

# ç”¨æ‹¬å·æŠŠæ•´ä¸ªæ•°å­—æ¨¡å¼åŒ…èµ·æ¥ï¼ˆæœ‰ä¸€ä¸ªæ•è·ç»„ï¼‰
RE_NUM = r'(-?(?:\d{1,3}(?:,\d{3})+|\d+)(?:\.\d+)?)'


def normalize_train_cost(df: pd.DataFrame, source_file: str) -> pd.DataFrame:
    cols = [str(c) for c in df.columns.tolist()]
    out = pd.DataFrame()

    # 1) å›ºå®šå­—æ®µæ˜ å°„
    for name in ["Flow","Origin Terminal","Route","Dest Terminal","Service Scope","Lead-Time(Day)","valid from","valid to","remark"]:
        pats = STD_COLS.get(name, [name])
        col = pick_first_match(cols, pats)
        out[name] = df[col] if col else np.nan

    # Lead-Time(Day) æ•°å€¼åŒ–
    if "Lead-Time(Day)" in out.columns:
        out["Lead-Time(Day)"] = pd.to_numeric(out["Lead-Time(Day)"], errors="coerce")

    # å°å·¥å…·ï¼šæå–ç¬¬ä¸€ä¸ªæ•°å­—
    def _num(s: pd.Series) -> pd.Series:
        s = s.astype(str).str.replace("\u00A0", " ", regex=False).str.strip()
        x = s.str.extract(RE_NUM, expand=False)
        x = x.str.replace(",", "", regex=False)
        return pd.to_numeric(x, errors="coerce").fillna(0.0)

    # 2) leasingï¼šæ•°å€¼åŒ–
    leasing_col = detect_leasing_col(cols)
    leasing_num = _num(df[leasing_col]) if leasing_col else pd.Series(0.0, index=df.index)
    out["leasing"] = leasing_num

    # 3) costï¼šæŠŠæ‰€æœ‰å« costï¼ˆæ’é™¤ forecastï¼‰çš„åˆ—ç›¸åŠ 
    cost_cols = [c for c in cols if ("cost" in c.lower()) and ("forecast" not in c.lower())]
    if cost_cols:
        parts = [_num(df[c]).rename(c) for c in cost_cols]
        cost_sum = pd.concat(parts, axis=1).sum(axis=1)
    else:
        cost_sum = pd.Series(0.0, index=df.index)

    # æœ€ç»ˆ cost = æ‰€æœ‰ cost ä¹‹å’Œ + leasing
    out["cost"] = cost_sum + leasing_num

    # 4) Container Typeï¼šå–å« container çš„åˆ—çš„ç¬¬ä¸€ä¸ªéç©º
    container_cols = [c for c in cols if "container" in c.lower()]
    if container_cols:
        tmp = df[container_cols].astype(str).replace({"nan": np.nan, "None": np.nan}).bfill(axis=1)
        out["Container Type"] = tmp.iloc[:, 0].astype(str).str.strip()
        out.loc[out["Container Type"].isin(["", "nan", "None"]), "Container Type"] = np.nan

    # 5) æ–‡æœ¬åˆ—å»ç©ºæ ¼ 
    for c in ["Flow","Origin Terminal","Route","Dest Terminal","Service Scope","valid from","valid to","remark","Container Type"]:
        if c in out.columns:
            out[c] = out[c].astype(str).str.strip()

    # 6) åˆ—é¡ºåº
    ordered = [c for c in NEED_ORDER if c in out.columns]  
    if "Container Type" in out.columns and "Container Type" not in ordered:
        ordered.append("Container Type")
    out = out.reindex(columns=ordered)

    out["__source_file__"] = source_file
    return out

def fix_leasing(series):
    s = pd.Series(series).astype(str).str.replace("\u00A0"," ",regex=False).str.strip()
    x = s.str.extract(RE_NUM, expand=False).str.replace(",", "", regex=False)
    return pd.to_numeric(x, errors="coerce").fillna(0.0)


# ---------- Main ----------
def build_total_cost_table(df_buffer, df_train, df_truck,
                           remark_text: str = "",
                           payload40: float = None,
                           payload20: float = None,
                           overload_text: str = "",
                           service_desc: str = "") -> pd.DataFrame:
    # ---------- å°å·¥å…· ----------
    def _norm_cols(df):
        d = df.copy()
        d.columns = [c.strip() for c in d.columns]
        return d

    def _as_num(s):
        return pd.to_numeric(s, errors="coerce")
    # ---------- ç»Ÿä¸€åˆ—åç©ºæ ¼/å¤§å°å†™ ----------
    df_buffer = _norm_cols(df_buffer)
    df_train  = _norm_cols(df_train)
    df_truck  = _norm_cols(df_truck)

    # å…³é”®å­—æ®µç»Ÿä¸€ä¸º string å»ç©ºæ ¼ï¼Œé¿å…åˆå¹¶æ—¶åŒ¹é…å¤±è´¥
    for d in (df_buffer, df_train, df_truck):
        for k in ["Origin Terminal", "Route", "Dest Terminal", "Container Type"]:
            if k in d.columns:
                d[k] = d[k].astype("string").str.strip()

    # ---------- 1) Buffer + Train å››é”®åˆå¹¶ï¼Œå¾—åˆ° T-T åŸºç¡€ ----------
    merge_keys = ["Origin Terminal", "Route", "Dest Terminal", "Container Type"]
    missing_in_buffer = [k for k in merge_keys if k not in df_buffer.columns]
    missing_in_train  = [k for k in merge_keys if k not in df_train.columns]
    if missing_in_buffer:
        raise ValueError(f"Buffer ç¼ºå°‘å­—æ®µ: {missing_in_buffer}")
    if missing_in_train:
        raise ValueError(f"Train ç¼ºå°‘å­—æ®µ: {missing_in_train}")

    tt_base = df_buffer.merge(
        df_train,
        on=merge_keys,
        how="inner",
        suffixes=("", "_train")
    )

    # æ•°å€¼åŒ–
    if "Buffer" not in tt_base.columns:
        raise ValueError("Buffer è¡¨ä¸­ç¼ºå°‘ 'Buffer' åˆ—")
    for c in ["Buffer", "cost", "leasing", "Lead-Time(Day)"]:
        if c in tt_base.columns:
            tt_base[c] = _as_num(tt_base[c]).fillna(0)

    # T-T æˆæœ¬ï¼ˆæŒ‰ä½ çš„å£å¾„ï¼šBuffer + cost(åŒ…å«leasing)ï¼‰
    tt_base["TT_total"] = tt_base["Buffer"].fillna(0) + tt_base["cost"].fillna(0)
    # T-T æ—¶æ•ˆ = çº¯ç«è½¦æ®µæ—¶æ•ˆ
    tt_base["TT_leadtime"] = tt_base["Lead-Time(Day)"].fillna(0)

    # ç»„è£… T-T è®°å½•ï¼ˆCity/Province ç½®ç©ºï¼‰
    tt_final = pd.DataFrame({
        "Flow": tt_base["Flow"],
        "Pickup/Delivery City": "",
        "Province": "",
        "Origin Terminal": tt_base["Origin Terminal"],
        "Dest Terminal": tt_base["Dest Terminal"],
        "Route": tt_base["Route"],
        "Service Scope": "T-T",
        "Lead-Time(Day)": tt_base["TT_leadtime"],
        "valid from": tt_base["valid from"] if "valid from" in tt_base.columns else "",
        "valid to": tt_base["valid to"] if "valid to" in tt_base.columns else "",
        "Total Cost": tt_base["TT_total"]
    })

    def pick_col(df, candidates, default_val=""):
        for c in candidates:
            if c in df.columns:
                return df[c]
        return pd.Series([default_val] * len(df), index=df.index)

    # ---------- 2) D-Tï¼ˆå‡ºå£ï¼ŒWï¼‰ï¼šåŸå¸‚â†’å§‹å‘ç«™ çš„æ‹–è½¦ + T-T ----------
    truck_w = df_truck[df_truck["Route"].astype(str).str.upper().str.strip() == "W"].copy()
    tt_w    = tt_base[tt_base["Flow"].astype(str).str.upper().str.strip() == "W"].copy()

    dt_merge = tt_w.merge(
        truck_w,
        on="Origin Terminal",
        how="left",
        suffixes=("", "_truck")
    )

    # å…¼å®¹ä¸åŒåˆ—åï¼ˆæ˜¯å¦å¸¦ _truck åç¼€ï¼‰
    dt_merge["truck_cost"] = pd.to_numeric(pick_col(dt_merge, ["Cost_truck", "Cost"], 0), errors="coerce").fillna(0)
    dt_merge["truck_lt"]   = pd.to_numeric(pick_col(dt_merge, ["Lead-Time (Day)_truck", "Lead-Time (Day)"], 0), errors="coerce").fillna(0)
    dt_merge["DT_total"]    = dt_merge["TT_total"] + dt_merge["truck_cost"]
    dt_merge["DT_leadtime"] = dt_merge["TT_leadtime"] + dt_merge["truck_lt"]

    dt_final = pd.DataFrame({
        "Flow": dt_merge["Flow"],
        "Pickup/Delivery City": pick_col(dt_merge, ["Pickup/Delivery City", "Pickup/Delivery City_truck"]),
        "Province": pick_col(dt_merge, ["Province", "Province_truck"]),
        "Origin Terminal": dt_merge["Origin Terminal"],
        "Dest Terminal": dt_merge["Dest Terminal"],
        "Route": dt_merge["Route"],
        "Service Scope": "D-T",
        "Lead-Time(Day)": dt_merge["DT_leadtime"],
        "valid from": pick_col(dt_merge, ["valid from"], ""),
        "valid to": pick_col(dt_merge, ["valid to"], ""),
        "Total Cost": dt_merge["DT_total"],
    })

    # ---------- 3) T-Dï¼ˆè¿›å£ï¼ŒEï¼‰ï¼šåˆ°è¾¾ç«™â†’åŸå¸‚ çš„æ‹–è½¦ + T-T ----------
    truck_e = df_truck[df_truck["Route"].astype(str).str.upper().str.strip() == "E"].copy()
    tt_e    = tt_base[tt_base["Flow"].astype(str).str.upper().str.strip() == "E"].copy()

    td_merge = tt_e.merge(
        truck_e,
        left_on="Dest Terminal",
        right_on="Origin Terminal",
        how="left",
        suffixes=("", "_truck")
    )

    td_merge["truck_cost"] = pd.to_numeric(pick_col(td_merge, ["Cost_truck", "Cost"], 0), errors="coerce").fillna(0)
    td_merge["truck_lt"]   = pd.to_numeric(pick_col(td_merge, ["Lead-Time (Day)_truck", "Lead-Time (Day)"], 0), errors="coerce").fillna(0)

    # æ³¨æ„ï¼šåˆå¹¶åå·¦è¡¨çš„ç«è½¦â€œå§‹å‘ç«™â€åœ¨ 'Origin Terminal'ï¼Œ
    # å³è¡¨å¡è½¦çš„â€œèµ·ç‚¹ç«™â€ï¼ˆç­‰äºç«è½¦çš„åˆ°è¾¾ç«™ï¼‰åœ¨ 'Origin Terminal_truck'
    td_merge["TD_total"]    = td_merge["TT_total"] + td_merge["truck_cost"]
    td_merge["TD_leadtime"] = td_merge["TT_leadtime"] + td_merge["truck_lt"]

    td_final = pd.DataFrame({
        "Flow": td_merge["Flow"],
        "Pickup/Delivery City": pick_col(td_merge, ["Pickup/Delivery City", "Pickup/Delivery City_truck"]),
        "Province": pick_col(td_merge, ["Province", "Province_truck"]),
        # å–ç«è½¦â€œå§‹å‘ç«™â€ï¼ˆå·¦è¡¨ï¼‰
        "Origin Terminal": pick_col(td_merge, ["Origin Terminal"]),
        "Dest Terminal": td_merge["Dest Terminal"],
        "Route": td_merge["Route"],
        "Service Scope": "T-D",
        "Lead-Time(Day)": td_merge["TD_leadtime"],
        "valid from": pick_col(td_merge, ["valid from"], ""),
        "valid to": pick_col(td_merge, ["valid to"], ""),
        "Total Cost": td_merge["TD_total"],
    })


    # ---------- 4) åˆå¹¶ä¸‰ç±»è®°å½• ----------
    final_df = pd.concat([tt_final, dt_final, td_final], ignore_index=True)

    # ---------- 5) Handling Fee ----------
    def _norm_route(s):
        return (s.astype(str)
            .str.replace(r"[\u2013\u2014\u2212]", "-", regex=True) 
            .str.upper().str.strip())

    mask_w   = final_df["Flow"].astype(str).str.upper().str.strip() == "W"
    routecol = "Service Scope" 
    mask_tt  = _norm_route(final_df[routecol]) == "T-T"
    mask_dt  = _norm_route(final_df[routecol]) == "D-T"

    # åªå¯¹ W & T-T çš„è¡Œå‡ 200ï¼›D-T ä¸å‡
    final_df.loc[mask_w & mask_tt, "Total Cost"] = (
        _as_num(final_df.loc[mask_w & mask_tt, "Total Cost"]) - 200
    )
    final_df.loc[mask_w & mask_dt, "Total Cost"] = (
        _as_num(final_df.loc[mask_w & mask_dt, "Total Cost"]) - 200
    )

    final_df["Handling Fee"] = np.where(final_df["Flow"].astype(str).str.upper().str.strip() == "W", 200, 0)

    # ---------- 6) åˆ—é¡ºåºä¸æ•°å€¼ç±»å‹ ----------
    final_df["Lead-Time(Day)"] = _as_num(final_df["Lead-Time(Day)"])
    final_df["Total Cost"]     = _as_num(final_df["Total Cost"])
    # final_df = final_df[[c for c in final_cols if c in final_df.columns]]
    final_df["Route"] = final_df["Route"].replace({
        "ä¼ ç»Ÿçº¿è·¯": "Public Train",
        "å…¨ç¨‹æ—¶åˆ»è¡¨": "Super Express"
    })
    def _norm(s: pd.Series) -> pd.Series:
        return (s.astype(str)
                .str.strip()
                .str.replace(r"[\u2018\u2019\u2032]", "'", regex=True)  
                .str.replace(r"[\u2013\u2014\u2212]", "-", regex=True) 
                .str.upper())

    # 1. æˆéƒ½ â†’ Lodz çš„ Super Express æ”¹æˆ æˆéƒ½ â†’ Malaszewicze çš„ Public Train
    mask_out = (
        _norm(final_df["Origin Terminal"]).eq("CHENGDU") &
        _norm(final_df["Dest Terminal"]).eq("LODZ") &
        _norm(final_df["Route"]).eq("SUPER EXPRESS")
    )
    final_df.loc[mask_out, "Route"] = "Public Train"
    final_df.loc[mask_out, "Dest Terminal"] = "Malaszewicze"

    # 2. Lodz â†’ æˆéƒ½ çš„ Super Express æ”¹æˆ Malaszewicze â†’ æˆéƒ½ çš„ Super Express
    mask_in = (
        _norm(final_df["Origin Terminal"]).eq("LODZ") &
        _norm(final_df["Dest Terminal"]).eq("CHENGDU") &
        _norm(final_df["Route"]).eq("SUPER EXPRESS")
    )
    final_df.loc[mask_in, "Origin Terminal"] = "Malaszewicze"


    # ---------- Remark & å…¨å±€é™„åŠ åˆ— ----------
    final_df["Remark"] = remark_text or ""
    final_df["Extra cost of overload"] = overload_text or ""
    final_df["Service Description"] = service_desc or ""
    final_df["40' Payload Limited (ton)"] = payload40 if payload40 is not None else ""
    final_df["20' Payload Limited (ton)"] = payload20 if payload20 !=0 else ""

    # ---------- Text æ¡ä»¶å¡«å…… ----------
    def _norm_ct(s: str) -> str:
        if not isinstance(s,str): return ""
        x = s.strip().lower().replace("â€™","'")
        x = x.replace("hc","hq")
        return x

    # if "container type" in final_df.columns:
    #     ct_norm = final_df["container type"].astype(str).map(_norm_ct)
    #     is_40 = ct_norm.str.contains("40", na=False)
    #     is_20 = ct_norm.str.contains("20", na=False)
    #     final_df["40' Payload Limited (ton)"] = ""
    #     final_df["20' Payload Limited (ton)"] = ""
    #     final_df.loc[is_40,"40' Payload Limited (ton)"] = payload40 if payload40 is not None else ""
    #     final_df.loc[is_20,"20' Payload Limited (ton)"] = payload20 if payload20 is not None else ""

    # ---------- åˆ—é¡ºåº ----------
    ordered_cols = [
        "Flow","Pickup/Delivery City","Province","Origin Terminal","Dest Terminal","Route",
        "Service Scope","Lead-Time(Day)","valid from","valid to",
        "Total Cost","Handling Fee",
        "40' Payload Limited (ton)","20' Payload Limited (ton)","Extra cost of overload",
        "Service Description","Remark"
    ]
    final_df = final_df[[c for c in ordered_cols if c in final_df.columns]]
    return final_df

tab1, tab2 = st.tabs({"Data", "Text"})
# ---------- Train Data Processing ----------
with tab1:
    if train_files:
        dfs = []
        for f in train_files:
            try:
                df_raw = pd.read_excel(f)
            except Exception:
                f.seek(0)
                df_raw = pd.read_excel(f, sheet_name=0, engine="openpyxl")
            norm = normalize_train_cost(df_raw, f.name)
            dfs.append(norm)
        all_train = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(columns=NEED_ORDER)
        df_train = all_train.dropna(how="all")
        df_train = df_train.dropna(subset=["cost"])
        #df_train["leasing"] = fix_leasing(df_train["leasing"])
        # show combined table
        with st.expander("æŸ¥çœ‹åˆå¹¶åçš„Train Cost"):
            st.success(f"Train Cost å·²åŠ è½½ï¼Œåˆå¹¶å {len(df_train)} è¡Œã€‚")
            st.dataframe(df_train[NEED_ORDER], use_container_width=True)

    # ---------- Truck Data Processing ----------
    if truck_file:
        dfs_truck = []
        xls = pd.ExcelFile(truck_file)  # è¯»å– Truck æ–‡ä»¶
        sheets = xls.sheet_names[2:]  # ä»ç¬¬ä¸‰ä¸ª sheet å¼€å§‹è¯»å–
        for sheet in sheets:
            df_truck_raw = pd.read_excel(xls, sheet_name=sheet)
            dfs_truck.append(df_truck_raw)
        all_truck = pd.concat(dfs_truck, ignore_index=True) if dfs_truck else pd.DataFrame()
        # å»æ‰ç©ºç™½åˆ—
        all_truck = all_truck.dropna(axis=1, how='all')
        # å»æ‰ç©ºç™½è¡Œ
        all_truck = all_truck.dropna(axis=0, how='all')
        if 'Lead-Timeï¼ˆhour)' in all_truck.columns:
            all_truck['Lead-Time (Day)'] = np.ceil(all_truck['Lead-Timeï¼ˆhour)'] / 24).astype(int)
            all_truck.drop('Lead-Timeï¼ˆhour)', axis=1, inplace=True)
        # ä¿®æ”¹åˆ—å
        origin_col = [col for col in all_truck.columns if 'origin terminal' in col.lower()]
        if origin_col:
            all_truck['Origin Terminal'] = all_truck[origin_col]
            all_truck.drop(origin_col, axis=1, inplace=True)  
        route_col = [col for col in all_truck.columns if 'route' in col.lower()]
        if route_col:
            all_truck['Route'] = all_truck[route_col]
            all_truck.drop(route_col, axis=1, inplace=True)  
        pro_col = [col for col in all_truck.columns if 'province' in col.lower()]
        if pro_col:
            all_truck['Province'] = all_truck[pro_col]
            all_truck.drop(pro_col, axis=1, inplace=True)  

        # å¤„ç† cost åˆ—ï¼Œæ‰¾åˆ°åŒ…å« cost çš„åˆ—å¹¶é™¤ä»¥ 7
        cost_col = [col for col in all_truck.columns if 'cost' in col.lower()]
        if cost_col:
            all_truck['Cost'] = np.round(all_truck[cost_col[0]] / 7).astype(int)
            all_truck.drop(cost_col[0], axis=1, inplace=True)
        all_truck['Valid From'] = pd.to_datetime(all_truck['Valid From'], errors='coerce').dt.date
        all_truck['Valid To'] = pd.to_datetime(all_truck['Valid To'], errors='coerce').dt.date
        # Reorder columns
        column_order = [
            "Route",
            "Origin Terminal",
            "Pickup/Delivery City",
            "Province",
            "Lead-Time (Day)",
            "Valid From",
            "Valid To",
            "Cost"
        ]
        # Reorder the columns as per the new column_order list
        #df_truck = all_truck[column_order] if all(col in all_truck.columns for col in column_order) else all_truck
        df_truck = all_truck[column_order]
        # æ˜¾ç¤ºåˆå¹¶åçš„ Truck æ•°æ®
        with st.expander("æŸ¥çœ‹æ‹–è½¦è´¹æ•°æ®"):
            st.success(f"æ‹–è½¦è´¹æ•°æ®å·²åŠ è½½ï¼Œå…±{len(df_truck)} è¡Œã€‚")
            st.dataframe(df_truck, use_container_width=True)

    # ---------- Buffer Data Processing ----------
    if buffer_file:
        all_buffer = pd.read_excel(buffer_file)
        columns = ["Origin Terminal", "Route", "Dest Terminal", "Container Type", "Buffer"]
        df_buffer = all_buffer[columns]
        def _norm(s: pd.Series) -> pd.Series:
            return (s.astype(str)
                .str.strip()
                .str.replace(r"[\u2018\u2019\u2032]", "'", regex=True)  
                .str.replace(r"[\u2013\u2014\u2212]", "-", regex=True) 
                .str.upper())  # å¦‚éœ€å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
        df_buffer = df_buffer.dropna(how="all")
        mask_1 = (
            _norm(df_buffer["Origin Terminal"]).eq("MALASZEWICZE") &
            _norm(df_buffer["Dest Terminal"]).eq("CHENGDU")
            )
        df_buffer.loc[mask_1, ["Origin Terminal"]] = ["Lodz"]
        mask_2 = (
            _norm(df_buffer["Origin Terminal"]).eq("CHENGDU") &
            _norm(df_buffer["Dest Terminal"]).eq("MALASZEWICZE")
            )
        df_buffer.loc[mask_2, ["Route","Dest Terminal"]] = ["å…¨ç¨‹æ—¶åˆ»è¡¨","Lodz"]
        
        with st.expander("æŸ¥çœ‹Bufferæ•°æ®", expanded=True):
            st.success(f"Bufferæ•°æ®å·²åŠ è½½ï¼Œå…±{len(df_buffer)} è¡Œã€‚")
            # é¦–æ¬¡è¿›å…¥æ—¶ï¼ŒæŠŠåŸæ•°æ®æ”¾åˆ°ä¼šè¯é‡Œï¼Œé¿å…ç¼–è¾‘æ—¶é—ªå›
            if "buffer_edit_df" not in st.session_state:
                st.session_state["buffer_edit_df"] = df_buffer.copy()

            with st.form("buffer_edit_form"):
                edited = st.data_editor(
                    st.session_state["buffer_edit_df"],
                    use_container_width=True,
                    hide_index=True,
                    num_rows="dynamic",
                    column_config={
                        "Add_Fixed": st.column_config.NumberColumn("Add_Fixed", step=1.0, format="%.2f"),
                        "Add_Percent": st.column_config.NumberColumn("Add_Percent", step=0.01, format="%.4f",
                                            help="å¯è¾“å…¥0.05æˆ–5%ï¼›åå°å¯å†ç»Ÿä¸€ä¸ºå°æ•°"),
                        "remark": st.column_config.TextColumn("remark", max_chars=200),
                    },
                    # è‹¥ä½ åªæƒ³è®©æŸäº›åˆ—å¯ç¼–è¾‘ï¼Œå¡« disabled=[...ä¸å¯ç¼–è¾‘åˆ—...]
                    # disabled=[]
                )
                saved = st.form_submit_button("ä¿å­˜ Buffer ç¼–è¾‘")

        if saved:
            st.session_state["buffer_edit_df"] = edited.copy()
            st.success("å·²ä¿å­˜ Buffer ç¼–è¾‘å†…å®¹ã€‚")

        # â†“ åç»­å¤„ç†ç”¨è¿™ä¸ªå˜é‡ï¼ˆæŠŠç¼–è¾‘åçš„ç»“æœä½œä¸º df_buffer å¾€ä¸‹ä¼ ï¼‰
        df_buffer = st.session_state["buffer_edit_df"]

with tab2:
    st.header("Global Settings")
    defaults = {
        "payload40": 20,
        "payload20": 20,
        "overload_text": "250USD/40'/20'(20-23 ton)",
        "service_desc": "Block train (W&E)",
        "remark_text": (
            "1. WB leadtime include CN terminal customs landing time\n"
            "2. EB leadtime exclude CN terminal customs lead time of estimated 1-2 days\n"
            "3. Overload cost in case cargo weight more than 23 ton, please check with us case by case.\n"
            "4. Due to impact of Chinese New Year, if your pre/on carriage happen in week 4 to week 7, trucking fee will increase 30%."
        ),
    }
    for k, v in defaults.items():
        st.session_state.setdefault(k, v)

    st.number_input("40' Payload Limited (ton)", min_value=0.0, step=0.5, key="payload40")
    st.number_input("20' Payload Limited (ton)", min_value=0.0, step=0.5, key="payload20")
    st.text_input("Extra cost of overload", key="overload_text")
    st.text_input("Service Description", key="service_desc")
    st.text_area("Remarkï¼ˆæ•´è¡¨ç»Ÿä¸€ï¼Œå¯ç¼–è¾‘ï¼‰", height=160, key="remark_text")

    # â€”â€” å¯é€‰ï¼šæŠŠ final_df çš„åˆ—æ˜ å°„åˆ° HTML é‡ŒæœŸæœ›çš„å­—æ®µå
    # å¦‚æœä½ çš„ final_df åˆ—åå·²ç»åŒ¹é…ï¼Œå°±åˆ æ‰è¿™ä¸ª mapping
    COLUMN_MAP = {
        "Pickup/Delivery City": "Origin City/Terminal",
        "Province": "Province",
        "Origin Terminal": "Origin Terminal",
        "Dest Terminal": "Dest Terminal",
        "Service Scope": "Service Scope", 
        "Route": "Route",         
        "Lead-Time(Day)": "Lead-Time(Day)",
        "Total Cost": "Total Cost",
        "Handling Fee": "Handling Fee",
        "valid from": "Valid From",
        "valid to": "Valid To"
    }

    REQUIRED_COLS = list(COLUMN_MAP.values())

    def _prepare_df_for_html(df: pd.DataFrame) -> pd.DataFrame:
        # å¤åˆ¶ä¸€ä»½ï¼Œé¿å…ä¿®æ”¹åŸ df
        d = df.copy()

        # å¦‚æœä½ çš„ df æ˜¯å·¦è¾¹ä¸ºæºåˆ—ã€å³è¾¹ä¸ºç›®æ ‡åˆ—çš„æ˜ å°„ï¼š
        # å…ˆç¡®ä¿ç›®æ ‡åˆ—å­˜åœ¨
        for src, dst in COLUMN_MAP.items():
            if src in d.columns:
                if dst != src:
                    d[dst] = d[src]
            else:
                # ä¸å­˜åœ¨å°±è¡¥ç©ºåˆ—ï¼Œé¿å…å‰ç«¯å´©
                d[dst] = np.nan

        # åªä¿ç•™å‰ç«¯éœ€è¦çš„åˆ—ï¼Œå¹¶æŒ‰é¡ºåºæ’åˆ—
        d = d[REQUIRED_COLS]

        # æ•°å€¼/ç¼ºå¤±å€¼æ¸…æ´—ï¼ŒJSON é‡Œä¸å‡ºç° NaN
        d = d.replace({np.nan: None})
        # ä¿è¯é‡‘é¢æ˜¯æ•°å€¼ç±»å‹ï¼ˆå¯é€‰ï¼‰
        for col in ["Total Cost", "Handling Fee"]:
            if col in d.columns:
                d[col] = pd.to_numeric(d[col], errors="coerce").fillna(0).astype(float)

        return d

    def inject_df_into_html(df: pd.DataFrame, template_path: str) -> str:
        html = Path(template_path).read_text(encoding="utf-8")

        # æŠŠç¤ºä¾‹æ•°æ®å—ï¼šconst csvData = [...];
        # æ›¿æ¢ä¸ºæˆ‘ä»¬ç”Ÿæˆçš„ JSONï¼šconst csvData = <json>;
        payload = df.to_dict(orient="records")
        json_str = json.dumps(payload, ensure_ascii=False)

        pattern = r"const\s+csvData\s*=\s*\[(?:.|\n)*?\];"
        replacement = f"const csvData = {json_str};"
        new_html = re.sub(pattern, replacement, html)
        return new_html



if buffer_file and train_files and truck_file:
    # â€”â€” ç”Ÿæˆ final df â€”â€” #
    #final_df = build_total_cost_table(df_buffer, df_train, df_truck)
    final_df = build_total_cost_table(
        df_buffer=df_buffer,
        df_train=df_train,
        df_truck=df_truck,
        remark_text=st.session_state["remark_text"],
        payload40=st.session_state["payload40"],
        payload20=st.session_state["payload20"],
        overload_text=st.session_state["overload_text"],
        service_desc=st.session_state["service_desc"],
    )

    mask_tt = final_df["Service Scope"] == "T-T"
    final_df.loc[mask_tt, "Pickup/Delivery City"] = final_df.loc[mask_tt, "Origin Terminal"]
    final_df.loc[mask_tt, "Province"] = final_df.loc[mask_tt, "Province"]
    st.success(f"æ€»è¡¨ç”Ÿæˆå®Œæˆï¼š{len(final_df)} è¡Œ")
    with st.expander("é¢„è§ˆ"):
        st.dataframe(final_df, use_container_width=True)
        st.download_button(
            "ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ CSV",
            data=final_df.to_csv(index=False).encode("utf-8"),
            file_name="RC_Raw_DB.csv",
            mime="text/csv"
        )
    # â€”â€” æŒ‰é’®ï¼šå¯¼å‡º HTML â€”â€” #
    st.header("Export Rate Card HTML")
    if "final_df" in globals():
        df_ready = _prepare_df_for_html(final_df)
        html_template_path = "Rate Card.html"  
        if Path(html_template_path).exists():
            if st.button("ğŸ“¤ å¯¼å‡º Rate Card HTML"):
                out_html = inject_df_into_html(df_ready, html_template_path)
                st.download_button(
                    label="ä¸‹è½½ Rate Card.html",
                    data=out_html.encode("utf-8"),
                    file_name="Rate Card.html",
                    mime="text/html",
                    use_container_width=True
                )
                st.success("å·²ç”Ÿæˆå¹¶å¯ä¸‹è½½ç¦»çº¿å¯ç”¨çš„ HTMLã€‚")
        else:
            st.error("æ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ Rate Card.htmlï¼Œè¯·æŠŠæ¨¡æ¿æ”¾åˆ°ç¨‹åºåŒç›®å½•ã€‚")
    else:
        st.warning("final_df å°šæœªç”Ÿæˆæˆ–æœªåœ¨å½“å‰ä½œç”¨åŸŸã€‚è¯·å…ˆç”Ÿæˆ final_dfã€‚")
else:
    st.info("è¯·ä¸Šä¼ å®Œæ•´è¡¨æ ¼ã€‚")

if "final_df" in locals() and isinstance(final_df, pd.DataFrame) and not final_df.empty:
    if not st.session_state["hide_intro"]:
        st.session_state["hide_intro"] = True
        st.rerun()   # ç«‹åˆ»é‡ç»˜ï¼Œè¿™æ ·æœ¬æ¬¡å°±ä¸å†æ˜¾ç¤ºæ¨ªå¹…



